{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the Network Segmentation Environment\n",
    "class NetworkEnvironment:\n",
    "    def __init__(self, n_segments=5):\n",
    "        # Number of segments in the network\n",
    "        self.n_segments = n_segments\n",
    "        # Traffic volume and security levels for each segment (arbitrary values for simulation)\n",
    "        self.traffic_volumes = np.random.randint(1, 100, n_segments)\n",
    "        self.security_levels = np.random.randint(1, 10, n_segments)\n",
    "    \n",
    "    def get_state(self):\n",
    "        # Return the state as a combination of traffic and security levels (just for simplicity)\n",
    "        return np.concatenate([self.traffic_volumes, self.security_levels])\n",
    "    \n",
    "    def reset(self):\n",
    "        self.traffic_volumes = np.random.randint(1, 100, self.n_segments)\n",
    "        self.security_levels = np.random.randint(1, 10, self.n_segments)\n",
    "        return self.get_state()\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Action is the segmentation strategy. \n",
    "        Action is represented as a list of indices where network segmentation occurs.\n",
    "        Example: [0, 1, 2] means segments 0, 1, 2 are isolated.\n",
    "        \"\"\"\n",
    "        # Calculate new state after applying segmentation (simplified)\n",
    "        # For simplicity, let's assume traffic decreases with better segmentation.\n",
    "        for i in action:\n",
    "            self.traffic_volumes[i] = max(0, self.traffic_volumes[i] - 10)  # Decrease traffic in segmented segments\n",
    "        \n",
    "        # Calculate reward: higher reward for optimal traffic and security distribution\n",
    "        reward = np.sum(self.traffic_volumes) - np.sum(self.security_levels)\n",
    "        \n",
    "        # New state after segmentation\n",
    "        new_state = self.get_state()\n",
    "        \n",
    "        return new_state, reward\n",
    "\n",
    "# Q-Learning Agent\n",
    "class QLearningAgent:\n",
    "    def __init__(self, n_actions, n_states, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "        self.alpha = alpha  # learning rate\n",
    "        self.gamma = gamma  # discount factor\n",
    "        self.epsilon = epsilon  # exploration-exploitation tradeoff\n",
    "        self.q_table = np.zeros((n_states, n_actions))\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        \"\"\"\n",
    "        Choose action using epsilon-greedy strategy\n",
    "        \"\"\"\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            # Exploration: Random action\n",
    "            return random.randint(0, len(self.q_table[state]) - 1)\n",
    "        else:\n",
    "            # Exploitation: Action with the highest Q-value\n",
    "            return np.argmax(self.q_table[state])\n",
    "    \n",
    "    def learn(self, state, action, reward, new_state):\n",
    "        \"\"\"\n",
    "        Update Q-table using the Q-learning formula\n",
    "        \"\"\"\n",
    "        best_future_q = np.max(self.q_table[new_state])\n",
    "        current_q = self.q_table[state, action]\n",
    "        self.q_table[state, action] = current_q + self.alpha * (reward + self.gamma * best_future_q - current_q)\n",
    "\n",
    "# Training the Q-learning agent to optimize network segmentation\n",
    "def train_network_segmentation(n_episodes=1000):\n",
    "    env = NetworkEnvironment(n_segments=5)\n",
    "    agent = QLearningAgent(n_actions=32, n_states=100)  # Simplified for a small state-action space\n",
    "\n",
    "    rewards = []\n",
    "    for episode in range(n_episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        for t in range(100):  # Max steps per episode\n",
    "            action = agent.choose_action(state)\n",
    "            # Convert action to segmentation strategy\n",
    "            action_segments = [i for i in range(len(state)) if action & (1 << i)]\n",
    "            new_state, reward = env.step(action_segments)\n",
    "            agent.learn(state, action, reward, new_state)\n",
    "            total_reward += reward\n",
    "            state = new_state\n",
    "        rewards.append(total_reward)\n",
    "    \n",
    "    # Plot rewards to see the learning process\n",
    "    plt.plot(range(n_episodes), rewards)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Reinforcement Learning for Network Segmentation Optimization')\n",
    "    plt.show()\n",
    "\n",
    "# Main function to train and evaluate the agent\n",
    "if __name__ == \"__main__\":\n",
    "    train_network_segmentation(n_episodes=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
